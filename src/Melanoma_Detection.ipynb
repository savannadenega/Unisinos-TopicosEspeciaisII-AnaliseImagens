{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Melanoma_Detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uY1ce_ZRzH-o"
      },
      "source": [
        "# Melanoma Detection\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Melanoma.jpg/300px-Melanoma.jpg)\n",
        "\n",
        "Melanoma is a type of skin cancer. It is the common type of skin cancer. On surfing the internet, we will come images of Melanoma which have a dark-black spot on the skin. We'll create a Siamese Convolutional Neural Network with TensorFlow using this notebook to detect two classes : **Melanoma and Non-Melanoma**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QMsw8k3p0F5l"
      },
      "source": [
        "## 1) Importing the packages\n",
        "We import the TensorFlow package along with NumPy and Keras. Also, we set the verbosity of TensorFlow to `tf.logging.ERROR` so that only errors are being printed in the output.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wlo35vcvKqEc",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# tf.logging.set_verbosity( tf.logging.ERROR )\n",
        "\n",
        "print( tf.__version__ )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VuTDoJy-01zV"
      },
      "source": [
        "## 2) Downloading the preprocessed data\n",
        "Processing and loading of data on a notebook could be time-consuming, so we directly download the processed data from GitHub.  The data was collected and processed in these steps :\n",
        "\n",
        "Images ->\n",
        "\n",
        "1. Images of Melanoma were collected from the internet. Some images of healthy skin were also collected.\n",
        "2. Due to the lesser amount of data, the images were augmented to increase their number upto 5041. Also, they were resize to dimensions 32 * 32 pixels.\n",
        "3. The RGB values were normalized ( brought down to the range ( 0 , 1 ) ).\n",
        "4. Converted to NumPy array of shape ( 5041 ,  32 , 32 , 3 ) to improve the image manipulation.\n",
        "\n",
        "Labels ->\n",
        "\n",
        "1. Pairs of images were generated. \n",
        "2. If both the images in that pair belonged to the same class, then the label of 1 was assigned, else 0 was assigned.\n",
        "3. Converted to NumPy array of shape ( 5041 , 1 ) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fd8nXVRIKvXu",
        "colab": {}
      },
      "source": [
        "\n",
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get( 'https://github.com/gabcastro/Unisinos-TopicosEspeciaisII-AnaliseImagens/raw/master/files/melanoma_images_processed.zip' )\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iWWVQnKn-Yuw"
      },
      "source": [
        "## 3) Reshaping the data\n",
        "\n",
        "We had total 5041 images and 5041 labels. We made a split of 4500-541 for training and validation respectively.\n",
        "\n",
        "* We squeezed the last 3 dimensions of the image array. Hence the shape transforms into ( 5041 , 32 , 32 , 3 ) -> ( 5041 , 3072 )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yb-LtlscLefH",
        "colab": {}
      },
      "source": [
        "\n",
        "DIMEN = 32\n",
        "\n",
        "X1 = np.load( 'x1.npy')\n",
        "X2 = np.load( 'x2.npy')\n",
        "Y = np.load( 'y.npy')\n",
        "\n",
        "X1 = X1.reshape( ( X1.shape[0]  , DIMEN**2 * 3  ) ).astype( np.float32 )\n",
        "X2 = X2.reshape( ( X2.shape[0]  , DIMEN**2 * 3  ) ).astype( np.float32 )\n",
        "\n",
        "train_X1 = X1[ : 4500 ] \n",
        "train_X2 = X2[ : 4500 ] \n",
        "train_Y = Y[ : 4500 ] \n",
        "\n",
        "test_X1 = X1[ 4500 : ]\n",
        "test_X2 = X2[ 4500 : ] \n",
        "test_Y = Y[ 4500 : ]\n",
        " \n",
        "print(  train_X1.shape )\n",
        "print(  train_X2.shape )\n",
        "print(  train_Y.shape )\n",
        "\n",
        "print(test_X1.shape )\n",
        "print(test_X1.shape )\n",
        "print(test_Y.shape) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RamzZuk-_dwA"
      },
      "source": [
        "## 4) Defining the Model\n",
        "\n",
        "We use Keras to build our Siamese Convolutional Neural Network. The layers will perform operations in this manner :\n",
        "\n",
        "1. Reshape the input ( from ( None , 3072 ) to ( None , 32 , 32 , 3 ) )\n",
        "2. Extract features using `Conv2D` and `MaxPooling2D` layers\n",
        "3. A `Dense` layer to produce a binary output using `sigmoid` activation function.\n",
        "4. Triplet Loss Function\n",
        "5. Produce a similarity score using `sigmoid`.\n",
        "\n",
        "Since our output is binary in nature we use `tf.keras.losses.binary_crossentropy` loss function with `tf.keras.optimizers.Adam` with a learning rate of 0.0001.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UaKnY6juLobf",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "input_shape = ( (DIMEN**2) * 3 , )\n",
        "convolution_shape = ( DIMEN , DIMEN , 3 )\n",
        "\n",
        "kernel_size_1 = ( 8 , 8 )\n",
        "kernel_size_2 = ( 6 , 6 )\n",
        "kernel_size_3 = ( 4 , 4 )\n",
        "\n",
        "pool_size_1 = ( 6 , 6 )\n",
        "pool_size_2 = ( 4 , 4 )\n",
        "\n",
        "strides = 1\n",
        "\n",
        "seq_conv_model = [\n",
        "\n",
        "\ttf.keras.layers.Reshape( input_shape=input_shape , target_shape=convolution_shape),\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D( 32, kernel_size=kernel_size_1 , strides=strides ,activation='relu' ),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=pool_size_1, strides=strides ),\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D( 64, kernel_size=kernel_size_2 , strides=strides ,activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=pool_size_2 , strides=strides),\n",
        "    \n",
        "    tf.keras.layers.Conv2D( 128, kernel_size=kernel_size_3 , strides=strides ,activation='relu'),\n",
        "    \n",
        "\ttf.keras.layers.Flatten(),\n",
        "\t\n",
        "\ttf.keras.layers.Dense( 3076 , activation=tf.keras.activations.sigmoid )\n",
        "\n",
        "]\n",
        "\n",
        "seq_model = tf.keras.Sequential( seq_conv_model )\n",
        "\n",
        "input_x1 = tf.keras.layers.Input( shape=input_shape )\n",
        "input_x2 = tf.keras.layers.Input( shape=input_shape )\n",
        "\n",
        "output_x1 = seq_model( input_x1 )\n",
        "output_x2 = seq_model( input_x2 )\n",
        "\n",
        "distance_euclid = tf.keras.layers.Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] ))( [output_x1 , output_x2] )\n",
        "outputs = tf.keras.layers.Dense( 1 , activation=tf.keras.activations.sigmoid) ( distance_euclid )\n",
        "model = tf.keras.models.Model( [ input_x1 , input_x2 ] , outputs )\n",
        "\n",
        "model.compile( loss=tf.keras.losses.binary_crossentropy , optimizer=tf.keras.optimizers.Adam(lr=0.0001) , metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NSNkqng7BcO_"
      },
      "source": [
        "## 5) Training the model\n",
        "We trained the model for 25 epochs with a batch size of 100 samples.\n",
        "\n",
        "**Inputs > `train_X1` and `train_X2`**\n",
        "\n",
        "**Outputs > `train_Y`**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rEeKeOXNBDK",
        "colab": {}
      },
      "source": [
        "\n",
        "model.fit( [ train_X1 , train_X2 ] , train_Y , epochs=10 , batch_size=100 ) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8XHOHQWiCMXP"
      },
      "source": [
        "## 6) Evaluate the Model\n",
        "\n",
        "We evaluated the model for its loss and accuracy on `test_X1` and `test_X2` arrays.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KINck89AcNVy",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "\n",
        "metrics = model.evaluate( [ test_X1 , test_X2 ] , test_Y ) \n",
        "print( 'Loss of {} and Accuracy is {} %'.format( metrics[0] , metrics[1] * 100 ) ) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmzaLG6K9ikO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}